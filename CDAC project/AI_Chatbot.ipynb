{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 979
    },
    "id": "PD6MSnypxj2c",
    "outputId": "ce371d71-7474-4597-f6ac-30e45d9c2759"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flags</th>\n",
       "      <th>instruction</th>\n",
       "      <th>category</th>\n",
       "      <th>intent</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>question about cancelling order {{Order Number}}</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>I've understood you have a question regarding ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BQZ</td>\n",
       "      <td>i have a question about cancelling oorder {{Or...</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>I've been informed that you have a question ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BLQZ</td>\n",
       "      <td>i need help cancelling puchase {{Order Number}}</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>I can sense that you're seeking assistance wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BL</td>\n",
       "      <td>I need to cancel purchase {{Order Number}}</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>I understood that you need assistance with can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCELN</td>\n",
       "      <td>I cannot afford this order, cancel purchase {{...</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>I'm sensitive to the fact that you're facing f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26867</th>\n",
       "      <td>BL</td>\n",
       "      <td>I am waiting for a rebate of {{Refund Amount}}...</td>\n",
       "      <td>REFUND</td>\n",
       "      <td>track_refund</td>\n",
       "      <td>Thank you for sharing your situation regarding...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26868</th>\n",
       "      <td>BIL</td>\n",
       "      <td>how to see if there is anything wrong with my ...</td>\n",
       "      <td>REFUND</td>\n",
       "      <td>track_refund</td>\n",
       "      <td>Ensuring the accuracy of your restitution is o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26869</th>\n",
       "      <td>BLQZ</td>\n",
       "      <td>I'm waiting for a reimbjrsement of {{Currency ...</td>\n",
       "      <td>REFUND</td>\n",
       "      <td>track_refund</td>\n",
       "      <td>Firstly, I genuinely understand the importance...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26870</th>\n",
       "      <td>BL</td>\n",
       "      <td>I don't know what to do to see my reimbursemen...</td>\n",
       "      <td>REFUND</td>\n",
       "      <td>track_refund</td>\n",
       "      <td>I've understood you're unsure about how to che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26871</th>\n",
       "      <td>BL</td>\n",
       "      <td>I need to know if there is anything new on the...</td>\n",
       "      <td>REFUND</td>\n",
       "      <td>track_refund</td>\n",
       "      <td>It's completely understandable that you want t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26872 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       flags                                        instruction category  \\\n",
       "0          B   question about cancelling order {{Order Number}}    ORDER   \n",
       "1        BQZ  i have a question about cancelling oorder {{Or...    ORDER   \n",
       "2       BLQZ    i need help cancelling puchase {{Order Number}}    ORDER   \n",
       "3         BL         I need to cancel purchase {{Order Number}}    ORDER   \n",
       "4      BCELN  I cannot afford this order, cancel purchase {{...    ORDER   \n",
       "...      ...                                                ...      ...   \n",
       "26867     BL  I am waiting for a rebate of {{Refund Amount}}...   REFUND   \n",
       "26868    BIL  how to see if there is anything wrong with my ...   REFUND   \n",
       "26869   BLQZ  I'm waiting for a reimbjrsement of {{Currency ...   REFUND   \n",
       "26870     BL  I don't know what to do to see my reimbursemen...   REFUND   \n",
       "26871     BL  I need to know if there is anything new on the...   REFUND   \n",
       "\n",
       "             intent                                           response  \n",
       "0      cancel_order  I've understood you have a question regarding ...  \n",
       "1      cancel_order  I've been informed that you have a question ab...  \n",
       "2      cancel_order  I can sense that you're seeking assistance wit...  \n",
       "3      cancel_order  I understood that you need assistance with can...  \n",
       "4      cancel_order  I'm sensitive to the fact that you're facing f...  \n",
       "...             ...                                                ...  \n",
       "26867  track_refund  Thank you for sharing your situation regarding...  \n",
       "26868  track_refund  Ensuring the accuracy of your restitution is o...  \n",
       "26869  track_refund  Firstly, I genuinely understand the importance...  \n",
       "26870  track_refund  I've understood you're unsure about how to che...  \n",
       "26871  track_refund  It's completely understandable that you want t...  \n",
       "\n",
       "[26872 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"Bitext_Sample_Customer_Support_Training_Dataset_27K_responses-v11.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_D2PWqYezdQv",
    "outputId": "2f4ff78f-e4cc-464e-ea02-c1227ac2e284"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null columns:\n",
      "flags          0\n",
      "instruction    0\n",
      "category       0\n",
      "intent         0\n",
      "response       0\n",
      "dtype: int64\n",
      "\n",
      "column datatypes:\n",
      "flags          object\n",
      "instruction    object\n",
      "category       object\n",
      "intent         object\n",
      "response       object\n",
      "dtype: object\n",
      "\n",
      "Total number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"null columns:\")\n",
    "print(data.isnull().sum())\n",
    "print()\n",
    "print(\"column datatypes:\")\n",
    "print(data.dtypes)\n",
    "print()\n",
    "duplicate_count = data.duplicated(keep=False).sum()\n",
    "print(f\"Total number of duplicate rows: {duplicate_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UOfAjsXUz3fu",
    "outputId": "f6c3a24a-9369-4cc0-858b-263374754d27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cancel_order' 'change_order' 'change_shipping_address'\n",
      " 'check_cancellation_fee' 'check_invoice' 'check_payment_methods'\n",
      " 'check_refund_policy' 'complaint' 'contact_customer_service'\n",
      " 'contact_human_agent' 'create_account' 'delete_account'\n",
      " 'delivery_options' 'delivery_period' 'edit_account' 'get_invoice'\n",
      " 'get_refund' 'newsletter_subscription' 'payment_issue' 'place_order'\n",
      " 'recover_password' 'registration_problems' 'review'\n",
      " 'set_up_shipping_address' 'switch_account' 'track_order' 'track_refund']\n",
      "['ORDER' 'SHIPPING' 'CANCEL' 'INVOICE' 'PAYMENT' 'REFUND' 'FEEDBACK'\n",
      " 'CONTACT' 'ACCOUNT' 'DELIVERY' 'SUBSCRIPTION']\n"
     ]
    }
   ],
   "source": [
    "print(data['intent'].unique())\n",
    "print(data['category'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "toX4TiCf0ClR",
    "outputId": "5084af50-a3a1-4ccb-d0b3-80d0cda3a59c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flags            object\n",
      "instruction      object\n",
      "category       category\n",
      "intent         category\n",
      "response         object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "data['category'] = pd.Categorical(data['category'])\n",
    "data['intent'] = pd.Categorical(data['intent'])\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-tJdTx81l00P",
    "outputId": "2be02893-196c-474b-f20c-1cc2567d3fd4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/mk/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to /home/mk/nltk_data...\n",
      "[nltk_data] Downloading package punkt_tab to /home/mk/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         instruction  \\\n",
      "0   question about cancelling order {{Order Number}}   \n",
      "1  i have a question about cancelling oorder {{Or...   \n",
      "2    i need help cancelling puchase {{Order Number}}   \n",
      "3         I need to cancel purchase {{Order Number}}   \n",
      "4  I cannot afford this order, cancel purchase {{...   \n",
      "\n",
      "                                 instruction_stemmed  \\\n",
      "0   question about cancel order { { order number } }   \n",
      "1  i have a question about cancel oorder { { orde...   \n",
      "2     i need help cancel puchas { { order number } }   \n",
      "3      i need to cancel purchas { { order number } }   \n",
      "4  i can not afford thi order , cancel purchas { ...   \n",
      "\n",
      "                              instruction_lemmatized  \\\n",
      "0  question about cancelling order { { Order Numb...   \n",
      "1  i have a question about cancelling oorder { { ...   \n",
      "2  i need help cancelling puchase { { Order Numbe...   \n",
      "3     I need to cancel purchase { { Order Number } }   \n",
      "4  I can not afford this order , cancel purchase ...   \n",
      "\n",
      "                                            response  \\\n",
      "0  I've understood you have a question regarding ...   \n",
      "1  I've been informed that you have a question ab...   \n",
      "2  I can sense that you're seeking assistance wit...   \n",
      "3  I understood that you need assistance with can...   \n",
      "4  I'm sensitive to the fact that you're facing f...   \n",
      "\n",
      "                                    response_stemmed  \\\n",
      "0  i 've understood you have a question regard ca...   \n",
      "1  i 've been inform that you have a question abo...   \n",
      "2  i can sens that you 're seek assist with cance...   \n",
      "3  i understood that you need assist with cancel ...   \n",
      "4  i 'm sensit to the fact that you 're face fina...   \n",
      "\n",
      "                                 response_lemmatized  \n",
      "0  I 've understood you have a question regarding...  \n",
      "1  I 've been informed that you have a question a...  \n",
      "2  I can sense that you 're seeking assistance wi...  \n",
      "3  I understood that you need assistance with can...  \n",
      "4  I 'm sensitive to the fact that you 're facing...  \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def stem_and_lemmatize_text(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return \" \".join(stemmed_words), \" \".join(lemmatized_words)\n",
    "\n",
    "\n",
    "data['instruction_stemmed'], data['instruction_lemmatized'] = zip(*data['instruction'].apply(stem_and_lemmatize_text))\n",
    "data['response_stemmed'], data['response_lemmatized'] = zip(*data['response'].apply(stem_and_lemmatize_text))\n",
    "\n",
    "print(data[['instruction', 'instruction_stemmed', 'instruction_lemmatized', 'response', 'response_stemmed', 'response_lemmatized']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LhnRLy4FnxzG",
    "outputId": "0fd8488c-0f90-4114-e59f-01311edcdc7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00' '00004587345current' '00108' ... 'zero' 'zip' 'zone']\n",
      "(26872, 6821)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "\n",
    "all_text = data['instruction_lemmatized'] + ' ' + data['response_lemmatized']\n",
    "vectorizer.fit(all_text)\n",
    "\n",
    "\n",
    "instruction_tfidf = vectorizer.transform(data['instruction_lemmatized'])\n",
    "response_tfidf = vectorizer.transform(data['response_lemmatized'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(vectorizer.get_feature_names_out())\n",
    "\n",
    "\n",
    "print(instruction_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XEKMZQ9eoKR2",
    "outputId": "6429913a-2aaf-4263-be8a-eda2f7590efb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_tfidf shape: (21497, 6821)\n",
      "X_test_tfidf shape: (5375, 6821)\n",
      "y_train shape: (21497,)\n",
      "y_test shape: (5375,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming 'intent' is your target variable and you have instruction_tfidf and response_tfidf\n",
    "X = data[['instruction_lemmatized', 'response_lemmatized']]  # Using original lemmatized text for splitting\n",
    "y = data['intent']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Now apply TF-IDF transformation to the split data\n",
    "X_train_tfidf = vectorizer.transform(X_train['instruction_lemmatized'] + ' ' + X_train['response_lemmatized'])\n",
    "X_test_tfidf = vectorizer.transform(X_test['instruction_lemmatized'] + ' ' + X_test['response_lemmatized'])\n",
    "\n",
    "# You have X_train_tfidf, X_test_tfidf, y_train, y_test for model training\n",
    "print(\"X_train_tfidf shape:\", X_train_tfidf.shape)\n",
    "print(\"X_test_tfidf shape:\", X_test_tfidf.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cvPuz0XUry0u",
    "outputId": "89f797fa-81bd-43d0-9e9d-0d937a17b564"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Performance:\n",
      "Accuracy: 0.9882790697674418\n",
      "Precision: 0.9884474942207078\n",
      "Recall: 0.9882790697674418\n",
      "F1-score: 0.9882903649711775\n",
      "\n",
      "\n",
      "Logistic Regression Performance:\n",
      "Accuracy: 0.9973953488372093\n",
      "Precision: 0.9974164582549064\n",
      "Recall: 0.9973953488372093\n",
      "F1-score: 0.9973956486030214\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mk/.local/lib/python3.8/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM Performance:\n",
      "Accuracy: 0.9992558139534884\n",
      "Precision: 0.9992577800643507\n",
      "Recall: 0.9992558139534884\n",
      "F1-score: 0.9992559009041629\n",
      "\n",
      "\n",
      "Random Forest Performance:\n",
      "Accuracy: 0.9903255813953489\n",
      "Precision: 0.9903932364909602\n",
      "Recall: 0.9903255813953489\n",
      "F1-score: 0.9903315281840581\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# 1. Naive Bayes\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train_tfidf, y_train)\n",
    "nb_predictions = nb_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate Naive Bayes\n",
    "print(\"Naive Bayes Performance:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, nb_predictions))\n",
    "print(\"Precision:\", precision_score(y_test, nb_predictions, average='weighted'))\n",
    "print(\"Recall:\", recall_score(y_test, nb_predictions, average='weighted'))\n",
    "print(\"F1-score:\", f1_score(y_test, nb_predictions, average='weighted'))\n",
    "print(\"\\n\")  # Add a newline for better readability\n",
    "\n",
    "# 2. Logistic Regression\n",
    "lr_classifier = LogisticRegression(max_iter=1000, solver='lbfgs', multi_class='auto')\n",
    "lr_classifier.fit(X_train_tfidf, y_train)\n",
    "lr_predictions = lr_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate Logistic Regression\n",
    "print(\"Logistic Regression Performance:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, lr_predictions))\n",
    "print(\"Precision:\", precision_score(y_test, lr_predictions, average='weighted'))\n",
    "print(\"Recall:\", recall_score(y_test, lr_predictions, average='weighted'))\n",
    "print(\"F1-score:\", f1_score(y_test, lr_predictions, average='weighted'))\n",
    "print(\"\\n\")\n",
    "\n",
    "# 3. Linear SVM\n",
    "svm_classifier = LinearSVC(max_iter=10000)\n",
    "svm_classifier.fit(X_train_tfidf, y_train)\n",
    "svm_predictions = svm_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate Linear SVM\n",
    "print(\"Linear SVM Performance:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, svm_predictions))\n",
    "print(\"Precision:\", precision_score(y_test, svm_predictions, average='weighted'))\n",
    "print(\"Recall:\", recall_score(y_test, svm_predictions, average='weighted'))\n",
    "print(\"F1-score:\", f1_score(y_test, svm_predictions, average='weighted'))\n",
    "print(\"\\n\")\n",
    "\n",
    "# 4. Random Forest\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train_tfidf, y_train)\n",
    "rf_predictions = rf_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate Random Forest\n",
    "print(\"Random Forest Performance:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, rf_predictions))\n",
    "print(\"Precision:\", precision_score(y_test, rf_predictions, average='weighted'))\n",
    "print(\"Recall:\", recall_score(y_test, rf_predictions, average='weighted'))\n",
    "print(\"F1-score:\", f1_score(y_test, rf_predictions, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2l_IApEr_Oy2",
    "outputId": "52d311ef-cbe2-4be5-8f45-40204e3cd352"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: I've realized that you need assistance with canceling purchase {{Order Number}}. To initiate the cancellation process, please follow these steps:\n",
      "\n",
      "1. Log Into Your Account: Access our platform by signing in to your {{Online Company Portal Info}}.\n",
      "2. Navigate to Your Orders: Once logged in, head over to the '{{Online Order Interaction}}' or '{{Online Order Interaction}}' section.\n",
      "3. Find Your Purchase: Within this section, locate the purchase associated with the order number {{Order Number}}.\n",
      "4. Initiate Cancellation: Look for the option labeled '{{Online Order Interaction}}' linked to your purchase. Please select it to begin the cancellation process.\n",
      "5. Complete Any Further Steps: The system might ask you a few questions to confirm or collect feedback. Please provide the necessary information as instructed.\n",
      "\n",
      "If you encounter any difficulties or have further questions along the way, our dedicated team is here to assist you. Reach out to us during {{Customer Support Hours}} at {{Customer Support Phone Number}} or use the Live Chat feature on our {{Website URL}}. We are committed to your satisfaction and are ready to guide you through the cancellation process.\"\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "user_input = input(\"Enter your message: \")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Apply the same preprocessing steps used for training data:\n",
    "    # 1. Tokenization using nltk.word_tokenize\n",
    "    # 2. Lemmatization using WordNetLemmatizer\n",
    "    words = nltk.word_tokenize(text)\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return \" \".join(lemmatized_words)\n",
    "\n",
    "preprocessed_input = preprocess_text(user_input)\n",
    "# Transform the preprocessed input using the trained vectorizer\n",
    "input_tfidf = vectorizer.transform([preprocessed_input])  # Note: [preprocessed_input] creates a list\n",
    "\n",
    "# Predict the intent using the trained SVM model\n",
    "predicted_intent = svm_classifier.predict(input_tfidf)[0]\n",
    "\n",
    "# Find a response from your dataset with the predicted intent\n",
    "possible_responses = data[data['intent'] == predicted_intent]['response'].tolist()\n",
    "\n",
    "# Select a response randomly to avoid repetition\n",
    "if possible_responses:  # Check if there are any responses for the intent\n",
    "    response = random.choice(possible_responses)\n",
    "else:\n",
    "    response = \"I'm sorry, I don't understand your request.\"  # Default response if no matching intent found\n",
    "\n",
    "print(\"Response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DPwjrZbOGbUt",
    "outputId": "8da57c68-5775-4a96-b6ae-d72c3a9d6040"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to svm_model.pkl\n",
      "Model saved to svm_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# prompt: create a pkl flie of this model and export it\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Assuming 'svm_classifier' is the trained model you want to pickle\n",
    "model_to_pickle = svm_classifier\n",
    "\n",
    "# Define the filename for the pickle file\n",
    "filename = 'svm_model.pkl'\n",
    "\n",
    "# Open the file in binary write mode\n",
    "with open(filename, 'wb') as f:\n",
    "    # Use pickle.dump to serialize the model and save it to the file\n",
    "    pickle.dump(model_to_pickle, f)\n",
    "\n",
    "print(f\"Model saved to {filename}\")\n",
    "\n",
    "# To verify, you can load the model back\n",
    "# with open(filename, 'rb') as f:\n",
    "# prompt: create a pkl flie of this model and export it\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Assuming 'svm_classifier' is the trained model you want to pickle\n",
    "model_to_pickle = svm_classifier\n",
    "\n",
    "# Define the filename for the pickle file\n",
    "filename = 'svm_model.pkl'\n",
    "\n",
    "# Open the file in binary write mode\n",
    "with open(filename, 'wb') as f:\n",
    "    # Use pickle.dump to serialize the model and save it to the file\n",
    "    pickle.dump(model_to_pickle, f)\n",
    "\n",
    "print(f\"Model saved to {filename}\")\n",
    "\n",
    "# To verify, you can load the model back\n",
    "# with open(filename, 'rb') as f:\n",
    "#     loaded_model = pickle.load(f)\n",
    "# print(\"Model loaded successfully.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
